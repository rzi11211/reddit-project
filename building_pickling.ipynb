{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following the pickling notebooks from chuck's 7.07 lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the cleaned and pre-processed data from Project 3\n",
    "df = pd.read_csv('~/dsi/submissions/Projects/project_3-master/cleaned_data/pre_proc_books_or_writing.csv').drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1616956496</td>\n",
       "      <td>['hope', 'underrated', 'general', 'public']</td>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1616956492</td>\n",
       "      <td>['try', 'short', 'stories', 'finished', 'produ...</td>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1616956472</td>\n",
       "      <td>['talking', 'right']</td>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1616956387</td>\n",
       "      <td>['isnt', 'cliché', 'fbi', 'doesnt', 'hire', 'c...</td>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1616956279</td>\n",
       "      <td>['thats', 'good', 'point', 'probably', 'thinki...</td>\n",
       "      <td>comments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc                                               text      type  \\\n",
       "0   1616956496        ['hope', 'underrated', 'general', 'public']  comments   \n",
       "1   1616956492  ['try', 'short', 'stories', 'finished', 'produ...  comments   \n",
       "2   1616956472                               ['talking', 'right']  comments   \n",
       "3   1616956387  ['isnt', 'cliché', 'fbi', 'doesnt', 'hire', 'c...  comments   \n",
       "4   1616956279  ['thats', 'good', 'point', 'probably', 'thinki...  comments   \n",
       "\n",
       "   subreddit  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37077, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with only submissions\n",
    "submission_df = df[df['type'] == 'submission']\n",
    "submission_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull a balanced sample\n",
    "sample = submission_df.groupby('subreddit').sample(n = 15_000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 'subreddit' descriptive again\n",
    "\n",
    "sample['subreddit'] = sample['subreddit'].map({0: 'books', 1: 'writing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up X and y\n",
    "\n",
    "X = sample['text']\n",
    "y = sample['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "books      0.5\n",
       "writing    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for baseline\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                 stratify=y,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add in some stopwords \n",
    "my_stop = ['like', 'im', 'just', 'dont', 'ive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(max_features = 12_500, ngram_range =(1, 2), stop_words=my_stop)),\n",
    "    ('logreg', LogisticRegression(C=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9049583333333333, 0.9008333333333334)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train), pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tvec': TfidfVectorizer(max_features=12500, ngram_range=(1, 2),\n",
       "                 stop_words=['like', 'im', 'just', 'dont', 'ive']),\n",
       " 'logreg': LogisticRegression(C=0.1)}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./models') \n",
    "except: \n",
    "    pass\n",
    "\n",
    "with open('./models/reddit_pipe.pkl', mode='wb') as pickle_out:\n",
    "    pickle.dump(pipe, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to unpickle\n",
    "\n",
    "with open('./models/reddit_pipe.pkl', mode='rb') as pickle_in:\n",
    "    pipe = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tvec': TfidfVectorizer(max_features=12500, ngram_range=(1, 2),\n",
       "                 stop_words=['like', 'im', 'just', 'dont', 'ive']),\n",
       " 'logreg': LogisticRegression(C=0.1)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hurrah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['books'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying a prediction from /r/books\n",
    "pipe.predict(['This is just something funny I realized yesterday when I went to my local Goodwill. I came across 3 Twilight books and realized that not only did I always see Twilight books at every thrift shop I go to, but they were always the same ones: Twilight, Eclipse, and Breaking Dawn (rarely ever see New Moon for some reason). Personally I‘m not really into the Twilight series anymore (middle school me would be screaming if she heard me say that) so instead of buying them I just kind of see them as a game. Everytime I go to a new thrift shop I search for them like “alright, where are you now?” And I always find one. So yeah.... that’s what I was thinking about today. If you also shop for books at thrift shops, are there any other books you always find there (The Fault in Our Stars is another book that seems to make a regular appearance)?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['writing'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying a prediction from /r/writing\n",
    "pipe.predict([\"Like you feel you have a really good story, but your writing ability would never do it justice? I'd be lying if I said I've never considered hiring an actual writer and just collaborating with them so the story is at least done right lol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your subreddit post: Like you feel you have a really good story, but your writing ability would never do it justice? I'd be lying if I said I've never considered hiring an actual writer and just collaborating with them so the story is at least done right lol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['writing'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_text = input('Please enter your subreddit post:')\n",
    "pipe.predict([user_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Photo by Oladimeji Ajegbile from Pexels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
